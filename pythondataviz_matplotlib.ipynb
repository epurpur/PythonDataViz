{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization in Pandas and Matplotlib ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our Data Visualization in Python Jupyter Notebook. We will learn to use the Pandas and Matplotlib libraries to take our data and do some data visualizations with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is learn some background information about the libraries and technologies we will be using. Because we are all using the Anaconda software distribution today, Anaconda comes with a lot of functionality installed on top of the base python libraries. This includes the pandas and matplotlib packages as well as the JupyterLab/Jupyter Notebook Environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JupyterLab/Jupyter Notebooks ##\n",
    "\n",
    "[Project Jupyter Homepage](https://jupyter.org/)\n",
    "\n",
    "The Jupyter environment is a web-based interactive computational environment for creating notebook-like documents. It supports several languages like python, R, Julia, etc. JupyterLab is the next generation user interface, which includes Jupyter Notebooks.\n",
    "\n",
    "In my opinion, they seem almost exactly the same but I'm sure people embedded within the development of the project would tell you differently.\n",
    "\n",
    "Think of the Jupyter environment as an interactive blog post. As you'll see, Jupyter allows you to show your code and explain it in a very neat, easy to follow way. Each cell either contains text (like this one) or code. When writing code, each cell basically functions like the command line or console. And as you'll see, each cell is LIVE and you can change your code on the fly. \n",
    "\n",
    "Jupyter really excels in situations like this class where we will be walking through a topic step by step. I can explain things, you can play with the code, and it is easy for everyone to see. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Step 1.</strong> Let's get started by importing the libraries we will be using. I will explain these later as we go. Because we are all using Anaconda, all of these libraries are already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Applications/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - matplotlib\n",
      "    - numpy\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-1.1.1               |   py37hb1e8313_0         7.8 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         7.8 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  pandas                               1.1.0-py37hb1e8313_0 --> 1.1.1-py37hb1e8313_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-1.1.1         | 7.8 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt     #I am pretty sure pyplot is the original functionality of matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 2. </strong> First we need to read in some data, so we can then work with it. This is a CSV sheet of career stats for professional baseball player, Mike Trout. Baseball is a numbers game so this gives us a nice, easy to use dataset to work use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"MikeTroutData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas ##\n",
    "\n",
    "[Pandas Documentation](https://pandas.pydata.org/)\n",
    "\n",
    "Pandas is an open source python library providing high-performance, easy-to-use data structures and data analysis tools. We will be using pandas to work with our data before feeding it into Matplotlib. Pandas can read from and write to many different data formats. It is intelligent in handling missing or bad data. You can easily reshape or pivot your data. It is optimized for performance. And it has a massive international user community so help and examples are readily available. \n",
    "\n",
    "## Pandas Dataframes ##\n",
    "\n",
    "The aforementioned easy to use data structure in pandas is called a [pandas dataframe](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html#dataframe). This is a tabular or spreadsheet-like view of your data, just as you'd see it in Excel. A pandas dataframe is a 2-dimensional labeled data structure with columns and rows. It is the most commonly used pandas object. Each one dimensional row or column is called a [pandas series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html) Along with the data, you can pass index (row labels) or columns as arguments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 3. </strong> Let's take a look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Age    G   AB    R    H  HR     BA    Salary  Awards\n",
      "0  2011   19   40  123   20   27   5  0.220     36000       0\n",
      "1  2012   20  139  559  129  182  30  0.326    492500       4\n",
      "2  2013   21  157  589  109  190  27  0.323    510000       3\n",
      "3  2014   22  157  602  115  173  36  0.287   1000000       3\n",
      "4  2015   23  159  575  104  172  41  0.299   6083000       3\n",
      "5  2016   24  159  549  123  173  29  0.315  16083000       3\n",
      "6  2017   25  114  402   92  123  33  0.306  20083000       2\n",
      "7  2018   26  140  471  101  147  39  0.312  34083000       3\n",
      "8  2019   27  134  470  110  137  45  0.291  36833333       1\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 4. </strong> We will want to slice and dice the data so let's see how to access the data by it's column header. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Age', 'G', 'AB', 'R', 'H', 'HR', 'BA', 'Salary', 'Awards'], dtype='object')\n",
      "\n",
      "['Year', 'Age', 'G', 'AB', 'R', 'H', 'HR', 'BA', 'Salary', 'Awards']\n",
      "\n",
      "0    2011\n",
      "1    2012\n",
      "2    2013\n",
      "3    2014\n",
      "4    2015\n",
      "5    2016\n",
      "6    2017\n",
      "7    2018\n",
      "8    2019\n",
      "Name: Year, dtype: int64\n",
      "\n",
      "0    123\n",
      "1    559\n",
      "2    589\n",
      "3    602\n",
      "4    575\n",
      "5    549\n",
      "6    402\n",
      "7    471\n",
      "8    470\n",
      "Name: AB, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.keys())     #a built in .keys() function\n",
    "print()\n",
    "print(df.columns.tolist())   # see the data in a list\n",
    "print()\n",
    "print(df['Year'])      #access an individual column using a dictionary syntax  (This is what I prefer)\n",
    "print()\n",
    "print(df.AB)           #access a column using the name as an attribute of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 5. </strong> I am renaming some of the columns we will be using, just for the sake of simplicity. It is easier to refer to these variable names than the entire syntax of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = df['Year']\n",
    "hits = df['H']\n",
    "at_bats = df['AB']\n",
    "home_runs = df['HR']\n",
    "salary = df['Salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 6. </strong> I can now use these variable names just like any other object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       36000\n",
      "1      492500\n",
      "2      510000\n",
      "3     1000000\n",
      "4     6083000\n",
      "5    16083000\n",
      "6    20083000\n",
      "7    34083000\n",
      "8    36833333\n",
      "Name: Salary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 7. </strong> We can also create new columns. We will start with a blank one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_column'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['new_column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 8. </strong> We can delete columns. I'll delete the nonsense column I just created, but more commonly this is used to clean your datasets of extraneous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['new_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['new_column'])      #this will result in an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 9. </strong> So far, we have only used our columns to access data and neglected rows. Rows are indexed starting at 0. If you think of other python objects, such as lists, the same concept applies. So the first row in the data would be in position 0 (the header row is excluded and treated separately).\n",
    "\n",
    "Accessing rows in pandas is done using the .loc() and .iloc() functions and is slightly more involved than just using the column header to access data. We will start with .iloc(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[:5])    #prints first 5 rows of data, notice the index row to the left of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 10. </strong> You can do slicing and similar operations just as you would with a python list using the .loc() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[2:3])      #prints only row at index 2  \n",
    "print()\n",
    "print(df.iloc[5:])     #prints everything row 5 and up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 11. </strong> The .loc() functions works somewhat counterintuitively but makes sense once you get the hang of it. Basically, you are accessing a row based on the value located in a column. See the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "young_age = df.loc[df['Age'] < 22]\n",
    "\n",
    "print(young_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 12. </strong> So you see above, I have effectively located the data for rows in which the column value is less than 22. Let's do another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_batting_average = df.loc[df['BA'] > .320]\n",
    "\n",
    "print(high_batting_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 13. </strong> One more example, let's create a new column and write data to it using a .loc() statement. We can actually do this all in one statement which I'll first show you and then explain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['BA'] > .320, 'High Batting Average'] = 'Yes'\n",
    "\n",
    "example = df[['BA', 'High Batting Average']]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 14. </strong> The above statement is a little more complicated. But as you can see, the first part is what we already did above. I selected rows with a batting average of > .320.  The second argument of this statement actually gives a name to the new column ('High Batting Average') and then populates it with the value of 'Yes' if the statement is true. So the interpreter iterates through each row of the dataframe to evaluate this statement. If it is true, the value 'Yes' is written to the new column. \n",
    "\n",
    "\n",
    "Pandas selection statements can get very tedious and there are endless variations and much more functionality than I have demonstrated. But for now, let's move on to visualizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization ##\n",
    "\n",
    "Finally, we get to the point where we can see our data in other ways than just a tabular format! Luckily for us, there are many data visualization libraries available in python. We will learn about just a few of the major ones, in particular Matplotlib. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib ##\n",
    "\n",
    "[Matplotlib documentation](https://matplotlib.org/)\n",
    "\n",
    "Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, the Python and IPython shells, the Jupyter notebook, web application servers, and four graphical user interface toolkits.\n",
    "Matplotlib tries to make easy things easy and hard things possible. You can generate plots, histograms, power spectra, bar charts, errorcharts, scatterplots, etc., with just a few lines of code. It integrates very nicely with Pandas, NumPy, and other related libraries.\n",
    "\n",
    "From [MatPlotLib's Wikipedia page](https://en.wikipedia.org/wiki/Matplotlib): Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plots\n",
    "\n",
    "<strong> Step 15. </strong> Let's get to it! This is a very simple plot of Mike Trout's hits per year. As you can see, I am using objects I already defined previously. Specifically these objects are columns from the Mike Trout stats dataframe (df). Previously I had defined the specific columns as their own variable name (year and hits). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(year, hits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 16. </strong> So as you see, I've got # of Hits on the Y Axis, and Year on the X Axis. Matplotlib provides many functions to produce different charts and plots such as plt.bar() shown above. The plt.show() function is needed to show the plot in the jupyter notebooks/ipython environment. But what are the year and hits objects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(year))\n",
    "print(type(hits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 17. </strong> As you see, these are pandas Series objects. Again, a series is a 1-Dimensional array of data. I'll be transforming my pandas dataframe to extract different series of objects, so I can plot them using matplotlib. You could also call these columns explicitly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df['Year'], df['H'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 18. </strong> Our first plot was as basic as it gets. Let's add some labels to make it look a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Year')\n",
    "plt.ylabel('# of Hits')\n",
    "plt.suptitle('Mike Trout Hits per year')\n",
    "plt.bar(year, hits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal Bar Plots\n",
    "\n",
    "<strong> Step 19. </strong> Let's turn our bar plot sideways. We do this using the plt.barh() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlabel('# of Hits')\n",
    "plt.ylabel('Year')\n",
    "plt.suptitle('Mike Trout Hits per year')\n",
    "plt.barh(year, hits, color='red')       #notice I changed the color argument. Blue is the default color\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Plot\n",
    "\n",
    "<strong> Step 20. </strong> We can also do simple line plots. Here is hits per year as a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Year')\n",
    "plt.ylabel('# of Hits')\n",
    "plt.grid()                    #I added a background grid\n",
    "plt.plot(year, hits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined plots\n",
    "\n",
    "<strong> Step 21. </strong> You can also put them together. \n",
    "In this plot, I have the # of hits plotted in blue as a bar chart, and number of At Bats in red as a line graph. \n",
    "\n",
    "But notice, our old labels don't work anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Year')\n",
    "plt.ylabel('# of Hits')\n",
    "plt.plot(year, at_bats, color='red')\n",
    "plt.bar(year, hits)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legends\n",
    "\n",
    "<strong> Step 22. </strong> A legend is probably the right thing to bring more clarity to our plot. This is a simple process. By adding a label argument to each plot function, the legend reads these. Lastly, the plt.legend() function is needed to show the legend on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Year')\n",
    "plt.suptitle('Mike Trout - At Bats and Hits per Year')\n",
    "plt.plot(year, at_bats, color='red', label='At Bats')\n",
    "plt.bar(year, hits, label='Hits')\n",
    "plt.legend()         #makes the legend happen!\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Bar Chart\n",
    "\n",
    "<strong> Step 23. </strong> We can stack bar charts on top of eachother\n",
    "\n",
    "In this chart, I am literally stacking home runs on top of hits. But you can get a visual picture on the ratio of home runs to overall hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Year')\n",
    "plt.suptitle('Mike Trout - Home Runs vs Total Hits')\n",
    "\n",
    "\n",
    "plt.bar(year, hits, label='Hits')\n",
    "plt.bar(year, home_runs, label='Home Runs')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped Bar Chart\n",
    "\n",
    "<strong> Step 24. </strong> In order to have my bar charts side by side, I need to move one of them to the side, and also make the bars skinnier so that everything fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Year')\n",
    "plt.suptitle('Mike Trout - Home Runs vs Total Hits')\n",
    "\n",
    "plt.xticks(rotation=45)         #rotates labels by 45 degrees\n",
    "plt.xticks(year)                #shows all years in label\n",
    "\n",
    "plt.bar(year, hits, width=.2, label='Hits')\n",
    "plt.bar(year+.2, home_runs, width=.2, label='Home Runs')        #moved the bars around manually\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels\n",
    "\n",
    "<strong> Step 25. </strong> I can add labels on my figures to show exact values. This is more complicated as you see I have included a loop. I had to google for examples of this and apply it for my own needs. This shows you that because there is so much functionality available in Matplotlib, you can customize your plot to look any way you want. But it can get complicated. Just remember, there is a huge user community on sites such as StackOverflow, personal blogs, etc for you to tap into. \n",
    "\n",
    "In the loop below, this is constructing the unique value of each column. I iterate through each bar and construct the text and position of each bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Year')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xticks(year)                #shows all years in label\n",
    "\n",
    "plt.ylabel('# of Hits')           \n",
    "plt.suptitle('Mike Trout Hits per year')\n",
    "\n",
    "for bar in plt.bar(year, hits):        \n",
    "    plt.text(bar.get_x() + .4,              #x position of label\n",
    "             bar.get_height() - 20,         #y position of label\n",
    "             bar.get_height(),              #actual value of label\n",
    "             ha='center',\n",
    "             va='bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<strong> Step 26. </strong> Remember, you can do math on the fly with your dataframe objects! Let's create a new column on the fly and use it for our next examples. This is the amount of money Mike Trout is paid per home run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_per_home_run = salary/home_runs\n",
    "\n",
    "print(type(cost_per_home_run))\n",
    "print(cost_per_home_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Step 27. </strong> In the following cell, I formatted the y axis labels and to do so used the Matplotlib ticker class (this is imported in our first cell with the other import statements). String formatting is not something I do often and I had to look for an example of how to do it. I knew I wanted to represent the dollar amounts in this situation, so again I googled for an answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xticks(year)\n",
    "\n",
    "formatter = ticker.FormatStrFormatter('$%.0f')     #formatting y axis as dollar amounts\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.ylabel('Price')           \n",
    "plt.suptitle('Mike Trout Pay Per Home Run')\n",
    "plt.bar(year, cost_per_home_run)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot\n",
    "\n",
    "<strong> Step 28. </strong> Now I'll give you some other examples of random plots, just to give you more ideas of what is possible. This next cell generates 50 random numbers to use in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)\n",
    "print(x)\n",
    "area = np.pi*3\n",
    "print(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, s=area, alpha=0.5)\n",
    "plt.title('Scatter plot pythonspot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Plotting Packages ##\n",
    "\n",
    "Matplotlib is not your only option! You may find you want different functionality, more advanced graphics, the desire to use what you already know from other languages, or are curious to explore what else is available. Here is a brief overview of some other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ggplot for python ##\n",
    "\n",
    "[ggplot homepage](http://ggplot.yhathq.com/)\n",
    "\n",
    "ggplot is a plotting system for Python based on R's ggplot2 and the Grammar of Graphics. The ggplot python library evolved out of the ggplot2 R-specific package. It seems to be accepted that ggplot2 (in R) is a more sophisticated graphics tool and provides more high end functionality. It is not clear to me if ggplot for python integrates all the functionality that ggplot2 has in R.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn ##\n",
    "\n",
    "[Seaborn homepage](https://seaborn.pydata.org/)\n",
    "\n",
    "Seaborn is a python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. It seems to be accepted as an extension to matplotlib functionality, particularly for statistical visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bokeh ##\n",
    "\n",
    "[Bokeh homepage](https://docs.bokeh.org/en/latest/index.html)\n",
    "\n",
    "Bokeh is different in that it does not depend on matplotlib and is geared toward generating visualizations in the web browser. It is meant to make interactive web visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which one should I use? ##\n",
    "\n",
    "There is no right or wrong answer. It depends what you are doing, what you are familiar with, or other influences in your life. Matplotlib is a good jack of all trades package for relatively basic plotting and graphing. It also integrates nicely with numpy and pandas, two other very common scientific packages.\n",
    "\n",
    "All these packages have large user communities and good documentation. My advice is to choose one you like and stick with it unless you find it does not have the functionality you are looking for.\n",
    "\n",
    "Reasons to use any given data visualization package/tool in python:\n",
    "\n",
    "- You are already familiar with it\n",
    "- Your advisor/professor already likes one and you live with that decision\n",
    "- You inherited code that is already using that package\n",
    "- You found a code example you liked online for a specific package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Help - You don't need to remember all of this! ##\n",
    "\n",
    "Here are a few resources I use when looking for code examples, solutions, etc.\n",
    "\n",
    "Google * Ex: \"How to make dictionary python\" * Ex: \"python decorators\"\n",
    "\n",
    "Stack Overflow (https://stackoverflow.com/) * A question/answer site for programming questions (actually, not just programming any more) * Not only python * DO NOT just ask questions, do your research first! * Odds are very high someone has already asked your question, especially as a novice\n",
    "\n",
    "Youtube - Corey Schafer (https://www.youtube.com/channel/UCCezIgC97PvUuR4_gbFUs5g) - If you have a question about a python programming concept, Corey Schafer has covered it\n",
    "\n",
    "Practice Python (http://www.practicepython.org/) * Coding challenges for programmers of all levels\n",
    "\n",
    "Python Tutor (http://pythontutor.com/) * Visualize what your code is doing step-by-step * Has limitations once you start importing libraries\n",
    "\n",
    "TalkPython Training (https://training.talkpython.fm/) * Not free * Really awesome courses that help you get \"real world\" project experience"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
